import asyncio
import random
import re
import logging
import sys
import time
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
import requests
import io
from PIL import Image
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
import dns.resolver
from twocaptcha import TwoCaptcha
from fake_useragent import UserAgent

# === CONFIG ===
BOT_TOKEN = "7619040891:AAF9pfQQme32XvhTfUb97jzky5w4ZEaBzwc"
CHAT_ID = "5172045930"
DEBUG = False
CAPTCHA_API_KEY = "71a87dcb7b9f01c390a0c26357a14788"
BLACKLIST_FILE = "blacklist.txt"

NAME = "Kevin Fang"
EMAIL = "kevandcoceo@hotmail.com"
PHONE = "+365433225"
ADDRESS = "123 Main St, New York, NY 10001"
SUBJECT = "Partnership with Concierge"
MESSAGE = "Hi I'm Kevin, I run a concierge service and I get a few issues with one of my clients, a politician and ive been subpeoned i need someone to represewnt me i have done nothing wrong kindly reach oput via email as im not in the states currently"

KEYWORDS = [
    "lawyers USA contact",
    "luxury lawyers enquiry",
    "lawyers Europe contact"
]
CONTACT_KEYWORDS = ["contact", "enquiry", "connect", "getintouch", "message", "reach", "touch"]

SEARCH_ENGINES = {
    "google": {
        "url": "https://www.google.com/search?q={}",
        "selector": ".g a"
    },
    "bing": {
        "url": "https://www.bing.com/search?q={}",
        "selector": ".b_algo h2 a"
    },
    "duckduckgo": {
        "url": "https://duckduckgo.com/?q={}",
        "selector": ".result__a"
    }
}

COOKIE_SELECTORS = [
    "#cookie-consent", ".cookie-banner", "#cookie-notice", "#cookiePolicy",
    "#acceptCookies", ".btn-cookies", ".cookie-accept", ".cookie-ok", "#gdpr-consent",
    ".cookie-agree", "#CybotCookiebotDialogBodyLevelButtonLevelOptinAllowAll",
    ".cc-btn", ".cookie-notice-actions button", "button:has-text('Accept')",
    "button:has-text(' Agree')", "button:has-text('Allow')", "button:has-text('OK')",
    "button:has-text('I accept')", "button:has-text('I agree')", "button:has-text('Consent')",
    "button:has-text('Got it')", "button:has-text('Close')", "button:has-text('Continue')",
    "button:has-text('Dismiss')", "button:has-text('Yes')", "button:has-text('Accept All')",
    "button:has-text('Allow All')", "button:has-text('I Understand')", "#cookie-accept",
    ".cookie-button", ".cookie-allow", "#acceptCookie", ".btn-cookie", "#cookieAgree",
    "#cookie-ok", "#gdpr-accept", ".js-cookie-accept", ".cookie-close"
]

TERMS_KEYWORDS = ["terms", "conditions", "privacy", "policy", "agree", "accept", "gdpr", "consent"]

POPUP_SELECTORS = [
    ".modal", ".popup", ".dialog", ".lightbox", "#modal", "#popup",
    "div[role='dialog']", "div[class*='modal']", "div[class*='popup']",
    ".overlay", ".notice", ".alert", ".notification", ".interstitial",
    ".slide-in", ".banner", ".ad-container", ".newsletter-popup"
]

CONTACT_NAV_PATTERNS = [
    "//a[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'contact')]",
    "//a[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'enquiry')]",
    "//a[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'connect')]",
    "//a[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'message')]",
    "//a[contains(@href, 'contact')]",
    "//a[contains(@href, 'enquiry')]",
    "//a[contains(@href, 'connect')]",
    "//a[contains(@id, 'contact')]",
    "//a[contains(@class, 'contact')]",
    "//a[contains(@title, 'Contact')]",
    "//button[contains(., 'Contact')]",
    "//button[contains(., 'Enquire')]"
]

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s", handlers=[logging.StreamHandler(sys.stdout)])
logger = logging.getLogger("lead_scraper")

# Load blacklist
try:
    with open(BLACKLIST_FILE, 'r') as f:
        blacklist = set(line.strip() for line in f)
except FileNotFoundError:
    blacklist = set(['google.com', 'bing.com', 'microsoft.com', 'outlook.com'])
    logger.warning("Blacklist file not found, using default blacklist")

visited_domains = set()

def get_domain(url):
    parsed = urlparse(url)
    domain = parsed.netloc.lower()
    if domain.startswith("www."):
        domain = domain[4:]
    return domain

def send_to_telegram(image_bytes, data):
    try:
        if not image_bytes or len(image_bytes) < 1024:
            logger.error("Invalid image for Telegram")
            return
        img = Image.open(io.BytesIO(image_bytes))
        buf = io.BytesIO()
        img.save(buf, format="JPEG", quality=85)
        buf.seek(0)
        caption = (
            f"Company: {data['company']}\n"
            f"Domain: {data['domain']}\n"
            f"MX Record: {data['mx_record']}\n"
            f"Leads: {data['leads']}\n"
            f"Contact Page: {data['contact_page']}\n"
            f"Status: {data['status']}"
        )[:1024]
        files = {"photo": ("screenshot.jpg", buf.getvalue())}
        data = {"chat_id": CHAT_ID, "caption": caption}
        with requests.Session() as session:
            r = session.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto",
                data=data,
                files=files,
                timeout=15
            )
            if r.status_code == 200:
                logger.info("Telegram: Message sent successfully")
            else:
                logger.error(f"Telegram error: {r.status_code} - {r.text}")
    except Exception as e:
        logger.error(f"Telegram send error: {e}")

async def handle_popups(page):
    for selector in POPUP_SELECTORS:
        try:
            popup = await page.query_selector(selector)
            if popup:
                close_btn = await popup.query_selector(
                    ".close, .dismiss, [aria-label='Close'], [aria-label='Dismiss'], "
                    "[title='Close'], [title='Dismiss'], .btn-close, .popup-close, "
                    ".modal-close, .close-button, .close-icon"
                )
                if not close_btn:
                    close_btn = await popup.query_selector(
                        "button:has-text('Close'), button:has-text('Dismiss'), "
                        "button:has-text('No thanks'), button:has-text('Maybe later'), "
                        "button:has-text('Not now'), button:has-text('Decline')"
                    )
                if close_btn:
                    await close_btn.scroll_into_view_if_needed()
                    await close_btn.click()
                    logger.info(f"Closed popup with selector: {selector}")
                    await asyncio.sleep(1)
                    return True
        except Exception as e:
            logger.debug(f"Popup close failed: {str(e)}")
    return False

async def handle_cookie_consent(page):
    for attempt in range(3):
        for sel in COOKIE_SELECTORS:
            try:
                btn = await page.query_selector(f"{sel}:visible") or await page.query_selector(sel)
                if btn:
                    await btn.scroll_into_view_if_needed()
                    await btn.click()
                    logger.info(f"Clicked cookie button using selector: {sel}")
                    await asyncio.sleep(1)
                    return True
            except Exception as e:
                logger.debug(f"Cookie click failed on {sel}: {str(e)}")
        await asyncio.sleep(1)
    return False

async def extract_company_name(page):
    try:
        meta_name = await page.query_selector('meta[name="author"]')
        if meta_name:
            company = await meta_name.get_attribute('content')
            if company:
                return company.strip()
        h1 = await page.query_selector('h1')
        if h1:
            return (await h1.text_content()).strip()
        title = await page.title()
        return title.split('-')[0].strip()
    except Exception as e:
        logger.error(f"Company name extraction error: {e}")
        return "Unknown"

async def extract_leads(page):
    try:
        html = await page.content()
        soup = BeautifulSoup(html, 'html.parser')
        emails = re.findall(r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}', html)
        phones = re.findall(r'\(\d{3}\) \d{3}-\d{4}|\d{3}-\d{3}-\d{4}', html)
        addresses = [addr.text.strip() for addr in soup.find_all('address')]
        return {
            "emails": emails[:3],
            "phones": phones[:3],
            "addresses": addresses[:3]
        }
    except Exception as e:
        logger.error(f"Leads extraction error: {e}")
        return {"emails": [], "phones": [], "addresses": []}

def get_mx_record(domain):
    try:
        answers = dns.resolver.resolve(domain, 'MX')
        return [answer.exchange.to_text() for answer in answers]
    except Exception as e:
        logger.error(f"MX record error for {domain}: {e}")
        return ["None"]

async def find_contact_pages(page, base_url):
    try:
        common_paths = [
            "/contact", "/contact-us", "/contactus", "/contact.html",
            "/contact.php", "/contact.aspx", "/en/contact", "/contact-form",
            "/get-in-touch", "/reach-out", "/connect", "/contacto", "/kontakt"
        ]
        found = set()
        for path in common_paths:
            contact_url = urljoin(base_url, path)
            if urlparse(contact_url).netloc == urlparse(base_url).netloc:
                found.add(contact_url)
        await page.goto(base_url, timeout=60000)
        await handle_popups(page)
        await handle_cookie_consent(page)
        contact_links = await page.query_selector_all(
            "a[href*='contact'], a:has-text('contact'), "
            "a[href*='enquiry'], a:has-text('enquiry'), "
            "a[href*='connect'], a:has-text('connect')"
        )
        for link in contact_links:
            href = await link.get_attribute("href") or ""
            if href and not href.startswith(("javascript:", "mailto:", "tel:")):
                full_url = urljoin(base_url, href)
                if urlparse(full_url).netloc == urlparse(base_url).netloc:
                    found.add(full_url)
        for pattern in CONTACT_NAV_PATTERNS:
            try:
                links = await page.query_selector_all(f"xpath={pattern}")
                for link in links:
                    href = await link.get_attribute("href") or ""
                    if href and not href.startswith(("javascript:", "mailto:", "tel:")):
                        full_url = urljoin(base_url, href)
                        if urlparse(full_url).netloc == urlparse(base_url).netloc:
                            found.add(full_url)
            except:
                continue
        return list(found)
    except Exception as e:
        logger.error(f"Find contact error: {e}")
        return []

async def try_fill_form(page, url, solver):
    try:
        await page.goto(url, timeout=60000)
        await handle_popups(page)
        await handle_cookie_consent(page)
        await asyncio.sleep(1)
        form_selectors = [
            "form", ".contact-form", "#contactForm", "#enquiryForm",
            ".wpcf7-form", ".gravity-form", ".forminator-form", ".elementor-form",
            "form[role='form']", ".gform_wrapper", ".contact-form-7", ".hs-form",
            ".form", ".webform", ".form-container", ".form-wrapper", ".form-contact",
            "form[class*='contact']", "form[id*='contact']", "form[name*='contact']"
        ]
        forms = []
        for selector in form_selectors:
            try:
                found_forms = await page.query_selector_all(selector)
                if found_forms:
                    forms.extend(found_forms)
            except:
                continue
        if not forms:
            logger.info(f"{url} → no forms found")
            return False, "No forms found", None
        logger.info(f"{url} → found {len(forms)} forms")
        for form in forms:
            filled = False
            inputs = await form.query_selector_all("input, textarea, select")
            for inp in inputs:
                t = (await inp.get_attribute("type") or "").lower()
                if t in ["hidden", "submit", "button", "image", "reset", "checkbox", "radio", "file"]:
                    continue
                ph = (await inp.get_attribute("placeholder") or "").lower()
                nm = (await inp.get_attribute("name") or "").lower()
                id_attr = (await inp.get_attribute("id") or "").lower()
                lbl_text = ""
                if id_attr:
                    lbl = await page.query_selector(f'label[for="{id_attr}"]')
                    lbl_text = (await lbl.text_content() or "").lower() if lbl else ""
                context = None
                field_text = ph + nm + id_attr + lbl_text
                if any(x in field_text for x in ["mail", "e-mail", "email"]):
                    context = "email"
                elif any(x in field_text for x in ["name", "fullname", "first", "last", "fname", "lname"]):
                    context = "name"
                elif any(x in field_text for x in ["phone", "mobile", "tel", "telephone"]):
                    context = "phone"
                elif any(x in field_text for x in ["subject", "title", "reason", "topic"]):
                    context = "subject"
                elif any(x in field_text for x in ["address", "street", "city", "zip", "location", "country"]):
                    context = "address"
                elif any(x in field_text for x in ["message", "comment", "enquiry", "content", "details"]):
                    context = "message"
                elif await inp.evaluate("el => el.tagName") == "TEXTAREA":
                    context = "message"
                if not context:
                    continue
                val = {
                    "email": EMAIL,
                    "name": NAME,
                    "phone": PHONE,
                    "subject": SUBJECT,
                    "address": ADDRESS,
                    "message": MESSAGE
                }[context]
                tag_name = await inp.evaluate("el => el.tagName")
                if tag_name == "SELECT":
                    try:
                        options = await inp.query_selector_all("option")
                        if len(options) > 1:
                            await options[1].click()
                            logger.info("Selected dropdown option")
                        else:
                            await inp.select_option(val)
                    except:
                        await inp.focus()
                        await page.keyboard.type(val, delay=100)
                else:
                    try:
                        await inp.fill(val)
                        logger.info(f"{context} field filled")
                    except:
                        await page.keyboard.type(val, delay=random.randint(50, 150))
                filled = True
            checkboxes = await form.query_selector_all("input[type='checkbox']")
            for cb in checkboxes:
                parent = await cb.query_selector("xpath=..")
                if parent:
                    parent_text = (await parent.text_content() or "").lower()
                    if any(term in parent_text for term in TERMS_KEYWORDS):
                        if not await cb.is_checked():
                            await cb.check()
                            logger.info("Checked terms checkbox")
                            filled = True
            if not filled:
                logger.info("No fillable fields found in form")
                continue
            recaptcha = await page.query_selector('.g-recaptcha')
            if recaptcha:
                sitekey = await recaptcha.get_attribute('data-sitekey')
                if sitekey:
                    try:
                        result = solver.recaptcha(sitekey=sitekey, url=url)
                        response = result['code']
                        await page.evaluate(f'document.getElementById("g-recaptcha-response").innerHTML="{response}";')
                        logger.info("Solved reCAPTCHA")
                    except Exception as e:
                        logger.error(f"CAPTCHA solving failed: {e}")
                        img = await page.screenshot()
                        return False, f"CAPTCHA solving failed: {str(e)}", img
            submit_selectors = [
                "input[type=submit]", "button[type=submit]", "button:has-text('Send')",
                "button:has-text('Submit')", "button:has-text('Contact')",
                "button:has-text('Enquire')", "button:has-text('Reach Out')",
                "button:has-text('Send Message')", "button:has-text('Request Quote')",
                "button:has-text('Get in Touch')", "button:has-text('Submit Form')",
                "button:has-text('Send Enquiry')", "button:has-text('Submit Request')"
            ]
            submitted = False
            for selector in submit_selectors:
                try:
                    btn = await form.query_selector(selector)
                    if btn:
                        await btn.scroll_into_view_if_needed()
                        await btn.click()
                        try:
                            await page.wait_for_navigation(timeout=5000)
                        except:
                            await asyncio.sleep(5)
                        submitted = True
                        break
                except:
                    continue
            if not submitted:
                try:
                    await form.evaluate("form => form.submit()")
                    await asyncio.sleep(5)
                    submitted = True
                except:
                    pass
            await asyncio.sleep(2)
            img = await page.screenshot()
            current_url = page.url
            html = (await page.content()).lower()
            success_indicators = [
                "thank you", "submitted", "we'll contact", "success",
                "received", "confirmation", "successfully", "message sent"
            ]
            status = "Filled but not submitted"
            if submitted:
                if any(x in current_url for x in ["thank", "success", "confirmation"]) or any(x in html for x in success_indicators):
                    status = "Form submitted successfully"
                else:
                    status = "Submitted but success not confirmed"
            return True, status, img
        return False, "No forms filled", None
    except PlaywrightTimeoutError:
        logger.error(f"Timeout on {url}")
        img = await page.screenshot()
        return False, "Timeout error", img
    except Exception as e:
        logger.error(f"Form fill error: {e}")
        img = await page.screenshot()
        return False, f"Error: {str(e)}", img

async def search_engine(page, engine, keyword):
    try:
        search_url = SEARCH_ENGINES[engine]["url"].format(keyword.replace(" ", "+"))
        await page.goto(search_url, timeout=60000)
        await page.wait_for_selector(SEARCH_ENGINES[engine]["selector"])
        links = await page.query_selector_all(SEARCH_ENGINES[engine]["selector"])
        search_domain = get_domain(SEARCH_ENGINES[engine]["url"].format(""))
        urls = []
        for link in links:
            href = await link.get_attribute('href')
            if href:
                link_domain = get_domain(href)
                if link_domain and link_domain != search_domain:
                    urls.append(href)
                    if len(urls) >= 5:
                        break
        return urls
    except Exception as e:
        logger.error(f"Search error on {engine} for '{keyword}': {e}")
        return []

async def process_url(page, url, solver):
    domain = urlparse(url).netloc
    if any(domain.endswith(bl) for bl in blacklist) or domain in visited_domains:
        logger.info(f"Skipping domain: {domain}")
        return
    visited_domains.add(domain)
    parsed = urlparse(url)
    base = f"{parsed.scheme}://{domain}"
    logger.info(f"Processing domain: {domain}")
    
    await page.goto(base, timeout=60000)
    await handle_popups(page)
    await handle_cookie_consent(page)
    
    company = await extract_company_name(page)
    leads = await extract_leads(page)
    mx_record = get_mx_record(domain)
    
    contact_pages = await find_contact_pages(page, base)
    if not contact_pages:
        logger.info(f"No contact pages found for {domain}")
        contact_pages = [urljoin(base, "/contact")]
    
    for cp in contact_pages:
        logger.info(f"Attempting contact page: {cp}")
        success, status, img = await try_fill_form(page, cp, solver)
        if success or img:
            data = {
                "company": company,
                "domain": domain,
                "mx_record": mx_record,
                "leads": leads,
                "contact_page": cp,
                "status": status
            }
            send_to_telegram(img, data)
            if success:
                break
        await asyncio.sleep(random.uniform(1, 3))
    
    await page.context.clear_cookies()

async def main():
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(
            headless=not DEBUG,
            args=["--window-size=1280,720", "--disable-blink-features=AutomationControlled"]
        )
        ua = UserAgent()
        context = await browser.new_context(
            viewport={"width": 1280, "height": 720},
            user_agent=ua.random
        )
        solver = TwoCaptcha(CAPTCHA_API_KEY)
        for kw in KEYWORDS:
            logger.info(f"Searching: {kw}")
            page = await context.new_page()
            for engine in SEARCH_ENGINES:
                logger.info(f"Searching on {engine}")
                urls = await search_engine(page, engine, kw)
                for url in urls:
                    try:
                        await process_url(page, url, solver)
                    except Exception as e:
                        logger.error(f"Error processing {url}: {e}")
                    await asyncio.sleep(random.uniform(1, 3))
                await page.close()
                page = await context.new_page()
            await asyncio.sleep(random.uniform(30, 60))
        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())

    C:\Users\Administrator\Desktop\form filler>py f4.py
2025-08-03 08:22:33,881 INFO Searching: lawyers USA contact
2025-08-03 08:22:34,175 INFO Searching on google
2025-08-03 08:23:08,972 ERROR Search error on google for 'lawyers USA contact': Page.wait_for_selector: Timeout 30000ms exceeded.
Call log:
  - waiting for locator(".g a") to be visible

2025-08-03 08:23:09,089 INFO Searching on bing
2025-08-03 08:23:40,101 ERROR Search error on bing for 'lawyers USA contact': Page.wait_for_selector: Timeout 30000ms exceeded.
Call log:
  - waiting for locator(".b_algo h2 a") to be visible

2025-08-03 08:23:40,244 INFO Searching on duckduckgo
2025-08-03 08:24:12,609 ERROR Search error on duckduckgo for 'lawyers USA contact': Page.wait_for_selector: Timeout 30000ms exceeded.
Call log:
  - waiting for locator(".result__a") to be visible

2025-08-03 08:24:51,242 INFO Searching: luxury lawyers enquiry
2025-08-03 08:24:52,451 INFO Searching on google


